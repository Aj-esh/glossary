title: Stochastic Gradient Descent (SGD)
related_terms:
 - stochastic-optimization
 - gradient-descent
---
Stocastic gradient algorithm picks [[random single dataset example]][1] 
or a subset of them at a time to calculate the values during [[backpropagation]][2] to 
substract from models parameters, weights and [[bias]][3] for updating them.

How do it choose to pick one in random? [[Random.]][4]] 

[1]: https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31
[2]: /terms/Backpropagation
[3]: /terms/Bias
[4]: https://web.stanford.edu/class/ee270/scribes/lecture16.pdf
